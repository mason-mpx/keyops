package system

import (
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	"net/url"
	"strings"
	"time"

	"github.com/fisker/zjump-backend/internal/model"
	"github.com/fisker/zjump-backend/internal/repository"
	"github.com/google/uuid"
)

type AssetSyncService struct {
	repo     *repository.AssetSyncRepository
	hostRepo *repository.HostRepository
}

func NewAssetSyncService(repo *repository.AssetSyncRepository, hostRepo *repository.HostRepository) *AssetSyncService {
	return &AssetSyncService{
		repo:     repo,
		hostRepo: hostRepo,
	}
}

// SyncNow ç«‹å³æ‰§è¡ŒåŒæ­¥
func (s *AssetSyncService) SyncNow(configID string) error {
	config, err := s.repo.GetByID(configID)
	if err != nil {
		return fmt.Errorf("é…ç½®ä¸å­˜åœ¨: %w", err)
	}

	if !config.Enabled {
		return fmt.Errorf("åŒæ­¥é…ç½®å·²ç¦ç”¨")
	}

	return s.executeSync(config)
}

// executeSync æ‰§è¡ŒåŒæ­¥
func (s *AssetSyncService) executeSync(config *model.AssetSyncConfig) error {
	startTime := time.Now()
	log.Printf("[AssetSync] Starting sync for config: %s (%s)", config.Name, config.Type)

	var syncedCount int
	var err error

	switch config.Type {
	case "prometheus":
		syncedCount, err = s.syncFromPrometheus(config)
	case "zabbix":
		syncedCount, err = s.syncFromZabbix(config)
	case "cmdb":
		syncedCount, err = s.syncFromCMDB(config)
	case "custom":
		syncedCount, err = s.syncFromCustomAPI(config)
	default:
		err = fmt.Errorf("unsupported sync type: %s", config.Type)
	}

	duration := int(time.Since(startTime).Seconds())
	status := "success"
	errorMsg := ""

	if err != nil {
		status = "failed"
		errorMsg = err.Error()
		log.Printf("[AssetSync]  Sync failed for %s: %v", config.Name, err)
	} else {
		log.Printf("[AssetSync]  Sync completed for %s: %d hosts synced", config.Name, syncedCount)
	}

	// æ›´æ–°åŒæ­¥çŠ¶æ€
	now := time.Now()
	config.LastSyncTime = &now
	config.LastSyncStatus = status
	config.SyncedCount = syncedCount
	config.ErrorMessage = errorMsg
	s.repo.Update(config)

	// åˆ›å»ºåŒæ­¥æ—¥å¿—
	logEntry := &model.AssetSyncLog{
		ID:           uuid.New().String(),
		ConfigID:     config.ID,
		Status:       status,
		SyncedCount:  syncedCount,
		ErrorMessage: errorMsg,
		Duration:     duration,
	}
	s.repo.CreateLog(logEntry)

	return err
}

// syncFromPrometheus ä»PrometheusåŒæ­¥
func (s *AssetSyncService) syncFromPrometheus(config *model.AssetSyncConfig) (int, error) {
	// è§£æè‡ªå®šä¹‰é…ç½®
	var promConfig struct {
		Query string `json:"query"` // è‡ªå®šä¹‰PromQLæŸ¥è¯¢
	}

	// ä»Configå­—æ®µè¯»å–é…ç½®
	query := "up" // é»˜è®¤æŸ¥è¯¢
	if config.Config != "" {
		if err := json.Unmarshal([]byte(config.Config), &promConfig); err == nil {
			if promConfig.Query != "" {
				query = promConfig.Query
			}
		}
	}

	log.Printf("[AssetSync] Using Prometheus query: %s", query)

	// ä½¿ç”¨query APIæŸ¥è¯¢
	queryURL := fmt.Sprintf("%s/api/v1/query?query=%s", config.URL, url.QueryEscape(query))

	client := &http.Client{Timeout: 30 * time.Second}
	req, err := http.NewRequest("GET", queryURL, nil)
	if err != nil {
		return 0, err
	}

	// æ·»åŠ è®¤è¯
	if config.AuthType == "basic" {
		req.SetBasicAuth(config.Username, config.Password)
	} else if config.AuthType == "token" {
		req.Header.Set("Authorization", "Bearer "+config.Token)
	}

	resp, err := client.Do(req)
	if err != nil {
		return 0, fmt.Errorf("failed to query Prometheus: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return 0, fmt.Errorf("Prometheus returned status: %d", resp.StatusCode)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return 0, err
	}

	var result struct {
		Status string `json:"status"`
		Data   struct {
			ResultType string `json:"resultType"`
			Result     []struct {
				Metric map[string]string `json:"metric"`
				Value  []interface{}     `json:"value"` // [timestamp, "value"]
			} `json:"result"`
		} `json:"data"`
	}

	if err := json.Unmarshal(body, &result); err != nil {
		return 0, fmt.Errorf("failed to parse response: %w", err)
	}

	// ç”¨äºå»é‡çš„mapï¼ˆkeyä¸ºIPåœ°å€ï¼‰
	ipMap := make(map[string]struct {
		job    string
		status string
	})

	// å¤„ç†ç»“æœï¼Œè¿‡æ»¤å’Œå»é‡
	for _, item := range result.Data.Result {
		instance, ok := item.Metric["instance"]
		if !ok || instance == "" {
			continue
		}

		// æå–IPåœ°å€ï¼ˆå»æ‰ç«¯å£ï¼‰
		ip := s.extractIP(instance)
		if ip == "" {
			log.Printf("[AssetSync] Skipping invalid instance: %s", instance)
			continue
		}

		// åªä¿ç•™IPåœ°å€æ ¼å¼ï¼ˆè¿‡æ»¤æ‰åŸŸåï¼‰
		if !s.isValidIP(ip) {
			log.Printf("[AssetSync] Skipping domain name: %s", instance)
			continue
		}

		// è§£ævalueï¼ˆ0=ç¦»çº¿ï¼Œ1=åœ¨çº¿ï¼‰
		status := "offline"
		if len(item.Value) >= 2 {
			if valueStr, ok := item.Value[1].(string); ok {
				if valueStr == "1" {
					status = "online"
				}
			}
		}

		// è·å–jobæ ‡ç­¾
		job := item.Metric["job"]
		if job == "" {
			job = "unknown"
		}

		// IPå»é‡ï¼šåŒä¸€ä¸ªIPåªä¿ç•™ç¬¬ä¸€ä¸ªæˆ–çŠ¶æ€ä¸ºonlineçš„
		if existing, exists := ipMap[ip]; exists {
			// å¦‚æœæ–°çš„æ˜¯onlineï¼Œæ›¿æ¢æ—§çš„
			if status == "online" && existing.status == "offline" {
				ipMap[ip] = struct {
					job    string
					status string
				}{job: job, status: status}
			}
			continue
		}

		// æ·»åŠ åˆ°map
		ipMap[ip] = struct {
			job    string
			status string
		}{job: job, status: status}
	}

	log.Printf("[AssetSync] Found %d unique IP addresses after filtering", len(ipMap))

	// å¤„ç†æ¯ä¸ªå”¯ä¸€çš„IPï¼ˆå¢é‡ç­–ç•¥ï¼šå­˜åœ¨å°±æ›´æ–°çŠ¶æ€ï¼Œä¸å­˜åœ¨å°±æ–°å¢ï¼‰
	syncedCount := 0
	updatedCount := 0
	createdCount := 0
	skippedCount := 0

	for ip, info := range ipMap {
		// æ£€æŸ¥ä¸»æœºæ˜¯å¦å·²å­˜åœ¨ï¼ˆä»¥IPä¸ºå”¯ä¸€keyï¼‰
		existing, _ := s.hostRepo.FindByIP(ip)
		if existing != nil {
			// ä¸»æœºå·²å­˜åœ¨ï¼Œåˆ¤æ–­çŠ¶æ€æ˜¯å¦éœ€è¦æ›´æ–°
			if existing.Status != info.status {
				if err := s.hostRepo.UpdateStatus(existing.ID, info.status); err != nil {
					log.Printf("[AssetSync]  Failed to update status for %s: %v", ip, err)
				} else {
					log.Printf("[AssetSync] ğŸ”„ Updated: %s (%s) [%s â†’ %s]",
						existing.Name, ip, existing.Status, info.status)
					updatedCount++
				}
			} else {
				// çŠ¶æ€æœªå˜ï¼Œè·³è¿‡
				skippedCount++
			}
			continue
		}

		// ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ä¸»æœº
		tags := fmt.Sprintf(`["prometheus","%s"]`, info.job)
		newHost := &model.Host{
			ID:             uuid.New().String(),
			Name:           fmt.Sprintf("prometheus-%s-%s", info.job, ip),
			IP:             ip,
			Port:           22,       // é»˜è®¤SSHç«¯å£
			DeviceType:     "server", // ä½¿ç”¨æ–°çš„è®¾å¤‡ç±»å‹å¸¸é‡
			Status:         info.status,
			Tags:           tags,
			ConnectionMode: "auto", // æ–°å¢å­—æ®µï¼šè¿æ¥æ¨¡å¼
			// æ³¨æ„ï¼šè®¤è¯ä¿¡æ¯å’Œåè®®è¯·é€šè¿‡ç³»ç»Ÿç”¨æˆ·é…ç½®
		}

		if err := s.hostRepo.Create(newHost); err != nil {
			log.Printf("[AssetSync]  Failed to create host %s: %v", ip, err)
			continue
		}

		log.Printf("[AssetSync]  Created: %s (%s) [%s]", newHost.Name, ip, info.status)
		createdCount++
	}

	syncedCount = updatedCount + createdCount
	log.Printf("[AssetSync]  Sync summary: %d total IPs | %d created | %d updated | %d skipped (no change)",
		len(ipMap), createdCount, updatedCount, skippedCount)

	return syncedCount, nil
}

// syncFromZabbix ä»ZabbixåŒæ­¥
func (s *AssetSyncService) syncFromZabbix(config *model.AssetSyncConfig) (int, error) {
	// Zabbix APIè°ƒç”¨
	// zabbixURL := fmt.Sprintf("%s/api_jsonrpc.php", config.URL)

	// 1. å…ˆç™»å½•è·å–token (å¦‚æœéœ€è¦)
	// 2. æŸ¥è¯¢hosts
	// 3. è§£æå¹¶åˆ›å»ºä¸»æœº

	// è¿™é‡Œæ˜¯ç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦æ ¹æ®Zabbix APIæ–‡æ¡£å®Œæ•´å®ç°
	return 0, fmt.Errorf("Zabbix integration not fully implemented yet")
}

// syncFromCMDB ä»CMDBåŒæ­¥
func (s *AssetSyncService) syncFromCMDB(config *model.AssetSyncConfig) (int, error) {
	// ä»CMDB APIè·å–èµ„äº§åˆ—è¡¨
	client := &http.Client{Timeout: 30 * time.Second}
	req, err := http.NewRequest("GET", config.URL, nil)
	if err != nil {
		return 0, err
	}

	// æ·»åŠ è®¤è¯
	if config.AuthType == "token" {
		req.Header.Set("Authorization", "Bearer "+config.Token)
	}

	resp, err := client.Do(req)
	if err != nil {
		return 0, err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return 0, fmt.Errorf("CMDB returned status: %d", resp.StatusCode)
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return 0, err
	}

	// è§£æCMDBå“åº”ï¼ˆæ ¼å¼éœ€è¦æ ¹æ®å®é™…CMDBç³»ç»Ÿè°ƒæ•´ï¼‰
	var hosts []struct {
		Hostname string   `json:"hostname"`
		IP       string   `json:"ip"`
		Port     int      `json:"port"`
		OS       string   `json:"os"`
		Tags     []string `json:"tags"`
	}

	if err := json.Unmarshal(body, &hosts); err != nil {
		return 0, err
	}

	syncedCount := 0
	for _, h := range hosts {
		existing, _ := s.hostRepo.FindByIP(h.IP)
		if existing != nil {
			continue
		}

		// åˆå¹¶tagså¹¶è½¬ä¸ºJSONå­—ç¬¦ä¸²
		allTags := append(h.Tags, "cmdb")
		tagsJSON, _ := json.Marshal(allTags)

		newHost := &model.Host{
			ID:         uuid.New().String(),
			Name:       h.Hostname,
			IP:         h.IP,
			Port:       h.Port,
			DeviceType: "linux",
			OS:         h.OS,
			Tags:       string(tagsJSON),
			// æ³¨æ„ï¼šè®¤è¯ä¿¡æ¯å’Œåè®®è¯·é€šè¿‡ç³»ç»Ÿç”¨æˆ·é…ç½®
		}

		if err := s.hostRepo.Create(newHost); err != nil {
			log.Printf("[AssetSync] Failed to create host %s: %v", h.IP, err)
			continue
		}

		syncedCount++
	}

	return syncedCount, nil
}

// syncFromCustomAPI ä»è‡ªå®šä¹‰APIåŒæ­¥
func (s *AssetSyncService) syncFromCustomAPI(config *model.AssetSyncConfig) (int, error) {
	// é€šç”¨HTTP APIè°ƒç”¨
	client := &http.Client{Timeout: 30 * time.Second}
	req, err := http.NewRequest("GET", config.URL, nil)
	if err != nil {
		return 0, err
	}

	if config.AuthType == "token" {
		req.Header.Set("Authorization", "Bearer "+config.Token)
	}

	resp, err := client.Do(req)
	if err != nil {
		return 0, err
	}
	defer resp.Body.Close()

	// ç®€åŒ–å®ç°
	return 0, fmt.Errorf("Custom API integration requires specific implementation")
}

// StartScheduler å¯åŠ¨å®šæ—¶åŒæ­¥è°ƒåº¦å™¨ï¼ˆä¸ä¼šç«‹å³æ‰§è¡ŒåŒæ­¥ï¼‰
func (s *AssetSyncService) StartScheduler() {
	log.Println("[AssetSync] ğŸ“… Scheduler started (interval: 5 minutes)")
	log.Println("[AssetSync]   Auto-sync will only run for ENABLED configurations")

	ticker := time.NewTicker(5 * time.Minute) // æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
	go func() {
		for range ticker.C {
			s.checkAndSync()
		}
	}()
}

// checkAndSync æ£€æŸ¥å¹¶æ‰§è¡Œéœ€è¦åŒæ­¥çš„é…ç½®
func (s *AssetSyncService) checkAndSync() {
	// åªè·å–å·²å¯ç”¨çš„é…ç½®
	configs, err := s.repo.GetEnabledConfigs()
	if err != nil {
		log.Printf("[AssetSync]  Failed to get enabled configs: %v", err)
		return
	}

	if len(configs) == 0 {
		// æ²¡æœ‰å¯ç”¨çš„é…ç½®ï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼Œä¿æŒå®‰é™
		return
	}

	log.Printf("[AssetSync]  Checking %d enabled sync configuration(s)...", len(configs))

	for _, config := range configs {
		// æ£€æŸ¥æ˜¯å¦åˆ°äº†åŒæ­¥æ—¶é—´
		if config.LastSyncTime != nil {
			nextSync := config.LastSyncTime.Add(time.Duration(config.SyncInterval) * time.Minute)
			if time.Now().Before(nextSync) {
				continue // è¿˜æ²¡åˆ°åŒæ­¥æ—¶é—´
			}
		}

		// å¼‚æ­¥æ‰§è¡ŒåŒæ­¥
		log.Printf("[AssetSync] â–¶ï¸  Triggering sync for: %s (%s)", config.Name, config.Type)
		go func(cfg model.AssetSyncConfig) {
			if err := s.executeSync(&cfg); err != nil {
				log.Printf("[AssetSync]  Sync failed for %s: %v", cfg.Name, err)
			}
		}(config)
	}
}

// extractIP ä»instanceä¸­æå–IPåœ°å€ï¼ˆå»æ‰ç«¯å£ï¼‰
// ä¾‹å¦‚: "192.168.1.100:9100" -> "192.168.1.100"
//
//	"192.168.1.100" -> "192.168.1.100"
func (s *AssetSyncService) extractIP(instance string) string {
	// å¦‚æœåŒ…å«ç«¯å£ï¼Œåˆ†å‰²å¹¶å–ç¬¬ä¸€éƒ¨åˆ†
	if strings.Contains(instance, ":") {
		parts := strings.Split(instance, ":")
		if len(parts) > 0 {
			return parts[0]
		}
	}
	return instance
}

// isValidIP éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„IPåœ°å€æ ¼å¼ï¼ˆæ’é™¤åŸŸåï¼‰
func (s *AssetSyncService) isValidIP(ip string) bool {
	// ä½¿ç”¨net.ParseIPéªŒè¯
	parsedIP := net.ParseIP(ip)
	if parsedIP == nil {
		return false
	}
	// åªæ¥å—IPv4åœ°å€
	if parsedIP.To4() != nil {
		return true
	}
	// ä¹Ÿå¯ä»¥æ¥å—IPv6ï¼Œæ ¹æ®éœ€è¦å¯ç”¨
	// return true
	return false
}
